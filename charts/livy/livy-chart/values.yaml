# Default values for livy-chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  # -- Image repository
  baseRepository: gcr.io/mapr-252711
  # -- Image Name
  imageName: livy-0.8.0
  # -- Overrides the image tag whose default is the chart appVersion.
  tag: "202406270245R"
  # -- Image pull policy
  pullPolicy: Always

#default spark image for spark applications created with livy
deImage: spark-3.5.1:v3.5.1.0.1

# -- Whether to create a default pull secret
createDefaultPullSecret: false
# -- Default pull secret name to be created, update it in imagePullSecrets's name
defaultPullSecret: imagepull

# -- Image pull secrets, name set to imagepull, change here if chart is creating defaultPullSecret
imagePullSecrets:
  - name: imagepull

# -- String to partially override `spark-operator.fullname` template (will maintain the release name)
nameOverride: ""

# -- String to override release name
fullnameOverride: ""

# -- restart policy
restartPolicy: "Always"

automountServiceAccountToken: true

#HPE tenant namespace info
tenantIsUnsecure: false

#HPE tenant namespace service account
serviceAccount:
  # Specifies whether a service account should be created
  # Default Service account is hpe-{{ ReleaseNamespace }}, which is created by Tenant operator.
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use. Please only use the tenant Service Account
  # This name is used only when create ServiceAccount option is set to true.
  name: "livy-server-sa"

#Create RBAC for the Service Account
rbac:
  #RBAC is created only when this flag is true and ServiceAccount.create is also true
  create: true

#set this only when configuring sssd
nativeSSSD: true

#enable ssh
ssh:
  enableMount: true

#enable this to include node affinity
nodeAffinity: true

# Bind user to session owner
# Use '%s' placeholder to be replaced with the session owner.
autosetNamespace:
  enable: true
  namespacePattern: "%s"
  driverSaPattern: "hpe-%s"
  executorSaPattern: "hpe-%s"

podSecurityContext: {}

securityContext:
  capabilities:
    add:
     - SYS_NICE
     - SYS_RESOURCE
  runAsGroup: 5000
  runAsUser: 5000
  # Pod needs to run as privileged on OpenShift environment to use hostPath mounts
  privileged: true

#container ports
ports:
  sshPort: 22
  livyHttpPort: 8998
  livyInternalPortStart: 10000
  livyInternalPortEnd: 10010

# resources -- Pod resource requests and limits
resources:
  limits:
    cpu: 2000m
    memory: 2Gi
    ephemeral-storage: 30Gi
  requests:
    cpu: 1000m
    memory: 1Gi
    ephemeral-storage: 30Gi

#owner Reference
ownerReference:
  overRide: false
  ownerReferences: {}

sessionRecovery:
  ##supported sessionRecovery Kind: disabled, pvc
  kind: disabled
  ##use this option to configure volumeClaimTemplate for kind pvc
  pvcTemplate:
    metadata:
      name: livy-sessionstore
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi

# Config map created by hive metastore. Used to connect livy with metastore
hiveSiteSource: ""

sparkHistoryServer:
  integrate: false
  pvcName: ""
  eventsDir: "maprfs:///apps/spark/sampletenant"

# Alpha feature
# Configure HTTPS for the Livy UI.
livySsl:
  enable: true
  # Leave the two following options blank to use tenant SSL Keystore.
  # Alternatively, to use a custom keystore, configure the following options and corresponding options in livy.conf.
  sslSecretName: ""
  secretMountPath: ""
  # sslSecretName: "livy-ssl-secret"
  # secretMountPath: /var/livy

# Alpha feature
# Data provided in "extraConfigs" will be added to configuration files through a K8S secret.
# Available files to configure: livy.conf, livy-client.conf and spark-defaults.conf.
extraConfigs:
  livy.conf: |
    # livy.keystore = /var/livy/ssl_keystore
    # livy.keystore.password = examplepass
    # livy.key-password = examplepass
  spark-defaults.conf: |
    spark.kubernetes.driver.label.sidecar.istio.io/inject=false
    spark.kubernetes.executor.label.sidecar.istio.io/inject=false
    # spark.sql.warehouse.dir maprfs:///apps/spark/spark-warehouse

# istio-related settings
istio:
  # Whether to enable istio sidecar injection on livy server pod
  enable: false
  # Istio virtual service settings
  virtualService:
    create: false
    endpoint: ""
    istioGateway: ""
    prefix: /
    customLabels: {}
  # If enabled - an authpolicy for oauth2-proxy with 'action':'CUSTOM' will be created
  authPolicy:
    create: false

# Add custom labels to livy server pod
customLabels:
