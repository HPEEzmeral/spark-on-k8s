apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-hive
  namespace: default
spec:
  type: Scala
  mode: cluster
  image: "gcr.io/mapr-252711/spark-3.3.1:202301161621R"
  imagePullPolicy: Always
  mainClass: com.hpe.examples.spark.sql.hive.SparkHiveExample
  mainApplicationFile: "local:///opt/spark/examples/jars/spark-hive-example-3.3.1.jar"
  sparkVersion: 3.3.1
  restartPolicy:
    type: Never
  imagePullSecrets:
    - imagepull
  volumes:
    - name: spark-pv
      persistentVolumeClaim:
        claimName: spark-hive-claim
  hadoopConfigMap: hivesite-cm
  driver:
    cores: 1
    coreLimit: "1000m"
    memory: "512m"
    labels:
      version: 3.3.1
    serviceAccount: metastore-spark
    volumeMounts:
      - name: spark-pv
        mountPath: /opt/spark/work-dir/spark-warehouse/
  executor:
    cores: 1
    coreLimit: "1000m"
    instances: 1
    memory: "512m"
    labels:
      version: 3.3.1
    volumeMounts:
      - name: spark-pv
        mountPath: /opt/spark/work-dir/spark-warehouse/
